{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JezFXSWHTssR",
        "outputId": "9982354a-8da7-44b0-8ee5-57fbb3c4ff8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/job\n",
        "recommendation.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/jobrecommendationDatasets') #Extracts the\n",
        "files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "BdEzuzHlT2Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install\n",
        "git+https://github.com/PyTorchLightning/pytorch-lightning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "metadata": {
        "id": "3DqKKvLdT9Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "tLL9FxfXT9W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "6KGSCamvT9ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_views = pd.read_csv('/jobrecommendationDatasets/Job_Views.csv')\n",
        "print(len(job_views))"
      ],
      "metadata": {
        "id": "zPrl2qb8T9bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_views_preprocess1 = pd.read_csv('/jobrecommendationDatasets/Job_Views.csv',usecols =[0,1,9,11])\n",
        "max_value = job_views_preprocess1['View.Duration'].max()\n",
        "print(\"max val=\",max_value)"
      ],
      "metadata": {
        "id": "VxgmPcPxT9de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_value = job_views_preprocess1['View.Duration'].min()\n",
        "print(\"min value = \",min_value)\n",
        "avg_value = job_views_preprocess1['View.Duration'].mean()\n",
        "print(\"avg val=\",avg_value)"
      ],
      "metadata": {
        "id": "5fzBDum_T9fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_min = 0\n",
        "new_max = 5"
      ],
      "metadata": {
        "id": "EuYItQ-0T9iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_views_to_review(x):\n",
        "  val = ((x-min_value)/(max_value-min_value))*(new_max-new_min) + new_min\n",
        "  if (val>0) :\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "UMvLhn3gUi1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_views_preprocess1['View.Duration'] = job_views_preprocess1['View.Duration'].apply(change_views_to_review)\n",
        "print(job_views_preprocess1['View.Duration'].head())"
      ],
      "metadata": {
        "id": "47cWp_yYUi3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_views_preprocess1['View.Start']= pd.to_datetime(job_views_preprocess1['View.Start'])\n",
        "print(job_views_preprocess1['View.Start'].head())"
      ],
      "metadata": {
        "id": "BtzZqjZjUi55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_views_preprocess1['rank_latest'] = job_views_preprocess1.groupby(['Applicant.ID'])['View.Start'] \\\n",
        ".rank(method='first', ascending=False)\n"
      ],
      "metadata": {
        "id": "MShK1uLVUi8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_job_views = job_views_preprocess1[job_views_preprocess1['rank_latest'] != 1]\n",
        "test_job_views = job_views_preprocess1[job_views_preprocess1['rank_latest'] == 1]"
      ],
      "metadata": {
        "id": "aDQ1bbdrUi-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns that we no longer need\n",
        "train_job_views = train_job_views[['Applicant.ID', 'Job.ID', 'View.Duration']]\n",
        "test_job_views = test_job_views[['Applicant.ID', 'Job.ID', 'View.Duration']]\n",
        "print(train_job_views.head())\n",
        "print(\"train length=\",len(train_job_views))\n",
        "print(test_job_views.head())\n",
        "print(\"test length=\",len(test_job_views))\n"
      ],
      "metadata": {
        "id": "6mt4nJ-DUjBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JobTrainDataset(Dataset):\n",
        "  def __init__(self, job_views_preprocess1, all_jobIds):\n",
        "    self.users, self.items, self.labels =\n",
        "    self.get_dataset(job_views_preprocess1, all_jobIds)\n",
        "  def __len__(self):\n",
        "    return len(self.users)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.users[idx], self.items[idx], self.labels[idx]\n",
        "  def get_dataset(self, ratings, all_jobIds):\n",
        "    users, items, labels = [], [], []\n",
        "    user_item_set =\n",
        "    set(zip(job_views_preprocess1['Applicant.ID'],\n",
        "    job_views_preprocess1['Job.ID']))\n",
        "    num_negatives = 5\n",
        "    for u, i in user_item_set:\n",
        "      users.append(u)\n",
        "      items.append(i)\n",
        "      labels.append(1)\n",
        "      for _ in range(num_negatives):\n",
        "        negative_item = np.random.choice(all_jobIds)\n",
        "        while (u, negative_item) in user_item_set:\n",
        "          negative_item = np.random.choice(all_jobIds)\n",
        "        users.append(u)\n",
        "        items.append(negative_item)\n",
        "        labels.append(0)\n",
        "    return torch.tensor(users), torch.tensor(items), torch.tensor(labels)\n"
      ],
      "metadata": {
        "id": "e7pURhZ4VAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCF(pl.LightningModule):\n",
        "  \"\"\" Neural Collaborative Filtering (NCF)\n",
        "  Args:\n",
        "  num_users (int): Number of unique users\n",
        "  num_items (int): Number of unique items\n",
        "  job_views_preprocess1(pd.DataFrame): Dataframe\n",
        "  containing the job viewed or not for training\n",
        "  all_jobIds (list): List containing all_jobIds (train +\n",
        "  test)\n",
        "  \"\"\"\n",
        "  def __init__(self, num_users, num_items, job_views_preprocess1, all_movieIds):\n",
        "    super().__init__()\n",
        "    self.user_embedding =\n",
        "    nn.Embedding(num_embeddings=num_users, embedding_dim=10)\n",
        "    self.item_embedding =\n",
        "    nn.Embedding(num_embeddings=num_items, embedding_dim=10)\n",
        "    self.fc1 = nn.Linear(in_features=20, out_features=64)\n",
        "    self.fc2 = nn.Linear(in_features=64, out_features=128)\n",
        "    self.fc3 = nn.Linear(in_features=128, out_features=256)\n",
        "    self.fc4 = nn.Linear(in_features=256, out_features=128)\n",
        "    self.fc5 = nn.Linear(in_features=128, out_features=32)\n",
        "    self.output = nn.Linear(in_features=32, out_features=1)\n",
        "    self.job_views_preprocess1 = job_views_preprocess1\n",
        "    self.all_jobIds = all_jobIds\n",
        "  def forward(self, user_input, item_input):\n",
        "    # Pass through embedding layers\n",
        "    user_embedded = self.user_embedding(user_input)\n",
        "    item_embedded = self.item_embedding(item_input)\n",
        "    # Concat the two embedding layers\n",
        "    vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
        "    # Pass through dense layer\n",
        "    vector = nn.ReLU()(self.fc1(vector))\n",
        "    vector = nn.ReLU()(self.fc2(vector))\n",
        "    vector = nn.ReLU()(self.fc3(vector))\n",
        "    vector = nn.ReLU()(self.fc4(vector))\n",
        "    vector = nn.ReLU()(self.fc5(vector))\n",
        "    # Output layer\n",
        "    pred = nn.Sigmoid()(self.output(vector))\n",
        "    return pred\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    user_input, item_input, labels = batch\n",
        "    predicted_labels = self(user_input, item_input)\n",
        "    loss = nn.BCELoss()(predicted_labels, labels.view(-1,1).float())\n",
        "    return loss\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters())\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(JobTrainDataset(self.job_views_preprocess1, self.all_jobIds),batch_size=512, num_workers=4)"
      ],
      "metadata": {
        "id": "AKybL_fPVARm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = job_views_preprocess1['Applicant.ID'].max()+1\n",
        "num_items = job_views_preprocess1['Job.ID'].max()+1\n",
        "all_jobIds = job_views_preprocess1['Job.ID'].unique()"
      ],
      "metadata": {
        "id": "b-lq_P4OVATe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NCF(num_users, num_items, train_job_views, all_jobIds)\n",
        "trainer = pl.Trainer(max_epochs=25, gpus=1, reload_dataloaders_every_epoch=True, progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
        "trainer.fit(model)\n",
        "\n",
        "# User-item pairs for testing\n",
        "test_user_item_set = set(zip(test_job_views['Applicant.ID'],\n",
        "test_job_views['Job.ID']))\n",
        "# Dict of all items that are interacted with by each user\n",
        "user_interacted_items = job_views_preprocess1.groupby('Applicant.ID')['Job.ID'].apply(list).to_dict()\n",
        "hits = []\n",
        "cnt = 0\n",
        "output = []\n",
        "for (u,i) in tqdm(test_user_item_set):\n",
        "  interacted_items = user_interacted_items[u]\n",
        "  not_interacted_items = set(all_jobIds) - set(interacted_items)\n",
        "  selected_not_interacted =\n",
        "  list(np.random.choice(list(not_interacted_items), 99))\n",
        "  test_items = selected_not_interacted + [i]\n",
        "  predicted_labels = np.squeeze(model(torch.tensor([u]*100),torch.tensor(test_items)).detach().numpy())\n",
        "  top10_items = [test_items[i] for i in\n",
        "  np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
        "  if(cnt ==0):\n",
        "    print(\"userid:\",u,\" recommended job id's:\",top10_items,\"\n",
        "    actual jobid :\",i)\n",
        "    cnt += 1\n",
        "    output.append(u)\n",
        "    output.append(top10_items)\n",
        "    output.append(i)\n",
        "  if i in top10_items:\n",
        "    hits.append(1)\n",
        "  else:\n",
        "    hits.append(0)"
      ],
      "metadata": {
        "id": "SHTPkAZ9VAXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))"
      ],
      "metadata": {
        "id": "y-4pJ7pAoxZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recommended jobs for user with userid:\",output[0],\" are \")\n",
        "print(\"============recommendations for you==============\")\n",
        "cnt = 1\n",
        "job_names = []\n",
        "company_names = []\n",
        "for x in output[1]:\n",
        "  job = jobs.loc[jobs['Job.ID'] == x, 'Title'].iloc[0]\n",
        "  joblist = job.split(\"@\")\n",
        "  job_names.append(joblist[0].strip())\n",
        "  if(len(joblist)>1):\n",
        "    company_names.append(joblist[1])\n",
        "  else:\n",
        "    company_names.append(\"\")\n",
        "  print(cnt,\")\",job)\n",
        "  cnt+= 1\n",
        "print(\"=================================================\")\n",
        "print(job_names)\n",
        "print(company_names)\n"
      ],
      "metadata": {
        "id": "O5RaD0-NoxcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#following are the images that are taken from google for display\n",
        "#purpose for the users\n",
        "im_job1 = Image.open('engineer.png')\n",
        "im_job2 = Image.open('fireman.png')\n",
        "im_job3 = Image.open('manager.png')\n",
        "im_job4 = Image.open('pilot.png')\n",
        "im_job5 = Image.open('policeman.png')\n",
        "im_job6 = Image.open('priest.png')\n",
        "im_job7 = Image.open('singer.png')\n",
        "im_job8 = Image.open('waiter.png')\n",
        "im_job9 = Image.open('welder.png')\n",
        "im_job10 = Image.open('engineer.png')"
      ],
      "metadata": {
        "id": "TsaSjaNkoxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_name = []\n",
        "image_name.append({'name':job_names[0], 'image':im_job1 })\n",
        "image_name.append({'name':job_names[1], 'image':im_job2 })\n",
        "image_name.append({'name':job_names[2], 'image':im_job3 })\n",
        "image_name.append({'name':job_names[3], 'image':im_job4 })\n",
        "image_name.append({'name':job_names[4], 'image':im_job5})\n",
        "image_name.append({'name':job_names[5], 'image':im_job6})\n",
        "image_name.append({'name':job_names[6], 'image':im_job7})\n",
        "image_name.append({'name':job_names[7], 'image':im_job8})\n",
        "image_name.append({'name':job_names[8], 'image':im_job9})\n",
        "image_name.append({'name':job_names[9], 'image':im_job10})"
      ],
      "metadata": {
        "id": "in9uQy6ipC1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import widgets\n",
        "import ipywidgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "print(\"following are your recommended jobs\")\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "# create output widget\n",
        "output = ipywidgets.widgets.Output()"
      ],
      "metadata": {
        "id": "j65hP0T3pFd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_desc = ['description']\n",
        "#job_info = [job_ids,job_names,company_names]\n",
        "data_type = [\"job ID\",\"job role\",\"job company\"]\n",
        "#df = pd.DataFrame(list(zip(job_col1, data_type)),columns=['',''])\n",
        "df = pd.DataFrame(data_type,columns=[''])"
      ],
      "metadata": {
        "id": "T6cUvJslpFgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_button_clicked(b):\n",
        "  # Display the message within the output widget.\n",
        "  with output:\n",
        "    clear_output()\n",
        "    print(\"job description\")\n",
        "    job_name = str(b.description)\n",
        "    job_index = 0\n",
        "    for i in range(len(job_names)):\n",
        "      if(job_name == job_names[i]):\n",
        "        job_index = i\n",
        "        break\n",
        "    df[job_desc[0]] =\n",
        "    [job_ids[job_index],job_names[job_index],company_names[job_index]]\n",
        "    print('\\n', 'jobname: ', str(b.description), '\\n')\n",
        "    display(df)"
      ],
      "metadata": {
        "id": "mySJh6F8pFj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of buttons, one for each star sign\n",
        "button_list = []\n",
        "for i in range(0,10):\n",
        "  button =  ipywidgets.widgets.Button(description=image_name[i]['name'])\n",
        "  button.on_click(on_button_clicked)\n",
        "  button_list.append(button)\n",
        "# arrange the job images and buttons into two rows\n",
        "grid = widgets.Grid(1, 5, header_row=True, header_column=True)\n",
        "newsize = (100, 100)\n",
        "for (row, col) in grid:\n",
        "  index = row*5+col\n",
        "  print(\"\\n\")\n",
        "  display(image_name[index]['image'].resize(newsize))\n",
        "  display(button_list[index])\n",
        "  for (row, col) in grid:\n",
        "    index = row*5+col\n",
        "    print(\"\\n\")\n",
        "    display(image_name[index+5]['image'].resize(newsize))\n",
        "    display(button_list[index+5])\n",
        "    # display output\n",
        "  #print('\\nSelect your job Sign by clicking the button\\n')\n",
        "  display(output)\n"
      ],
      "metadata": {
        "id": "VOU9SPbWpXX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PsPDpJWpXbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}